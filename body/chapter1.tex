% !Mode:: "TeX:UTF-8"

\chapter{引言}
\section{选题背景及意义}

随着博客、社交网络、以及云计算、物联网等技术的兴起，互联网上的数据正以前所未有的速度在不断的增长和累积，学术界、工业界甚至于政府机构都已经开始密切关注大数据问题，应该说大数据是互联网发展到一定阶段的必然产物，互联网用户的互动，企业和政府的信息发布，物联网传感器感应的实时信息每时每刻都在产生大量的结构化和非结构化数据，这些数据分散在整个网络体系内，体量极其巨大。基于这些大数据的各种新兴数据应用和数据服务也层出不穷，它们极大的满足了信息时代社会大众对高效、准确获取信息的强烈愿望。然而，在社会大众得到极大满足的同时，这些应用和服务的提供者则不得不面对海量数据所带来的各种压力和挑战。

由于现实世界中的许多应用场景都可以利用用图来表示。因此，将这些数据以图的结构进行存储则有利于分析、处理并发掘处蕴含在其中对经济、科技、教育等等领域非常宝贵的信息。与此同时，在生命健康科学、安全、金融服务等很多领域也存在类似的数据集，例如，交通线路图，报纸文献，用户行为分析[5]疾病暴发路径以及科学研究发表文章中的引用关系等。另外，还有许多其他图计算问题也有着重大的实际价值，如最小切割，连通分支等问题。这些大规模图数动辄就是数亿顶点，数十亿条边，据量之大更是前所未有。如何高效的处理大规模的图对象成为无数研究人员和研究组织争相分析和研究的热门对象。

随着对大规模图对象的研究的深入，衍生出许多适应于大规模图处理的框架和应用。


本文从兼容性、容错性与便捷性的角度考虑，提出了基于并行BSP模型的单机图处理系统GPSA。基于BSP模型的图处理过程主要有计算和通讯两个步骤。在传统的BSP模型中，由于图数据的局部性问题，计算和通讯两个步骤需要顺序执行，并且两个相邻的超级步之间需要一个额外的同步。在本文，GPSA利用Actor编程模型取代线程来改善系统的并发性和计算吞吐量；其次，结合Actor与BSP模型将图计算中顶点的计算和消息处理的过程解耦，降低两个相邻的超级步之间的依赖关系，使计算和通讯两个步骤以流水线的方式并行执行。另外，GPSA利用内存映射的方式来提高数据的读取和更新能力。通过不同的数据集对比，不同的单机系统的对比，GPSA不仅与分布式的BSP图处理系统具有较好的兼容性，还具有良好的图处理性能。

\section{国内外文献综述}
现有的大型图计算系统的分类没有严格的标准，从系统的适用场景及规模的角度出发，粗略分为两类：
\begin{itemize}
\item 分布式图计算系统
\item 单机图计算系统
\end{itemize}
本节分别针对这两类的国内外研究现状进行介绍和阐述。

\subsection{分布式系统}
数据是信息的载体,信息是数据的内涵,一般认为数据是信息系统的基础。利用计算机来处理数据,提取信息是信息系统的基本功能。在当今高度信息化的社会里,Web可以说是目前最大的信息系统,其数据具有海量、多样、异构、动态变化等特性。如何实现快速地从这些海量数据中提取出对企业有用的价值信息已成为程序员在开发应用软件的过程中碰到的最令人头疼的问题。 基于这个问题的出发点,本文在分析现有分布式储存和计算等关键技术基础上,结合对Hadoop的集群技术的研究以及自身的业务需求和实际软硬件实力,提出了一种基于Hadoop的海量数据处理模型,并从数据结构设计、程序流程组织和编程技术的使用等几个方面来介绍这个模型的开发方法,最后将该模型应用于大型网站的web日志数据预处理过程中。针对该模型我们还设计了一种有效的基于分布式的预处理模式。该模式首先在各分布式服务器上进行关联匹配,然后将各个服务器上的挖掘结果合成。这有利于减轻网络频繁的通讯负担,体现并行计算、异步挖掘、异构数据规约的优势。同时,它允许程序员可以不需要有什么并发处理或者分布式系统的经验,就可以处理超大的分布式系统得资源。除了数据挖掘之外,该模型还可以应用在诸如图片存储、搜索引擎、网格计算等需要处理大数据量的网络应用中。 本课题的特点是将研究的模型与实际业务应用相结合,利用前沿的分布式框架技术来很好的满足项目的需求,并将模型部署到实例当中,用实验结果来检验模型的实用价值,比如高效率、低成本、可拓展性和易维护性等。在与原来的预处理系统相融合的基础上,我们还对初级的模型进行了性能的优化,主要包括:简化规则的改进、多任务的优先级设定和网络负载平衡算法的优化。


通常已有的分布式计算框架并不是完全适合图计算，例如MapReduce。Map-Reduce[7]是由谷歌提出的一种基于Key-Value键值对的编程模型。用户需要自定义map()和reduce()两个函数。Map()函数用来处理Key-Value键值对并且负责生成一系列中间键值对，reduce()函数用来对具有相同Key的中间值进行归约。在分布式系统中，Map-Reduce模型可以很方便的实现大数据的并行计算。运行时系统处理输入输出、调度以及故障处理等。虽然Map-Reduce常常被用来解决大型图的问题,例如基于Map-Reduce的GBASE[8,9]和PEGASUS[10]，但是通常对图算法来说都不是最优的解决方案，也不是最合适的方案。对数据处理的基本模式有聚合以及类似SQL语句的查询方式等，但是这些扩展方式通常对大型图计算这种消息传递模型来说并不理想。
为解决上述问题Google的工程师们，以BSP[11]模型为基础，提出一种全新的以顶点为中心的图计算模型Pregel。BSP模型作为计算机语言和体系结构之间的桥梁，又称作桥模型。在BSP模型中，计算由一系列用全局同步分开的周期为L的计算组成，这些计算称为超级步。在一个超级步中，各处理器均执行局部操作，并且可以通过选路器接收和发送消息。然后作一全局检查，以确定该超级步是否一由所有的处理器完成。若是，则进行到下一个超级步，否则下一个L周期被分配给未曾完成的超级步。BSP模型强调了计算任务和通信任务的分开。此外，BSP放弃了程序局部性原理，简化程序的设计和实现。

Pregel[12]是一个基于BSP模型的分布式图计算框架。它最初的目的是用来解决PageRank计算问题。由于Map-Reduce并不适用于这种需要大量消息传递的场景，所以需要发展新的计算模型去完成这样的任务。Pregel的计算通过一系列以顶点为核心的超级步的迭代完成，在每一次迭代中，每个图中的顶点会接收来自上一次迭代的信息，并发送信息给其他顶点，同时可能修改其自身状态以及以它为顶点的出边的状态，甚至改变整个图的拓扑结构，该迭代过程持续到整个图中所有顶点完成收敛，即所有顶点由激活状态转换为不激活状态。在第0个超级步，所有顶点都处于激活状态，所有的激活顶点都会参与到所对应的超级步中计算。顶点通过将其自身的状态设置为停止表示他已经处于不激活状态，这就表示该顶点在该超级步中没有进一步的计算需要执行。如果顶点接收到消息，那么将会被唤醒并进入激活状态，
虽然图算法也可以被写成是一系列的链式MapReduce调用，但是需要将整个图的状态从一个阶段传输到另一个阶段，这样就需要很多的通信和随之而来的序列化和反序列化的开销。采用Pregel可以将顶点和边保存在执行的那台计算机上，而仅仅利用网络传输信息，通过引入BSP中超级步的概念来避免这样的情况。Pregel提供了一套完整的API接口，并具有较好的扩展性和容错机制。与Pregel以顶点为中心的处理不同，X-Stream[13]是以个以边为中心的共享内存的图处理框架。X-Stream使用基于边的scatter-gather编程模型，而在顶点中保存处理的状态。在Scatter阶段，所有边发送边上的更新值，在gather阶段则设置边上的更新值。
Pregel是严格的BSP模型，采用“计算-通信-同步”的模式完成大规模的图计算。在Pregel中图处理框架中依然存在一些缺陷，如pregel以顶点为中心的，但是在很多应用中是以若干组合的顶点为中心，在这样的场景下Pregel就不适合。此外，Pregel没有提供系统运行期间的重新分配以达到负载均衡，减少通讯的目的。于是，有很多学者提出了一些类Pregel的系统，并且针对上述的问题做出优化。
GraphLab[14]是为高效的机器学习算法提出的一种基于共享内存的分布式并行处理框架。GraphLab将数据抽象成图结构，将算法的执行过程抽象成Gather、Apply和Scatter三个步骤，其并行的核心思想是对顶点的切分和两端分区方案。与一般的BSP模型不同的是GraphLab总是在最近获得的数据上进行计算来保证计算过程的持续性。GraphLab的缺陷在于容错性，负载均衡等方面。Trinity也是一个基于内存的分布式系统，它主要关注如何在图计算过程中优化内存使用和降低通信代价，为此Trinity需要昂贵的高带宽设备。

Mizan[15]是一个类Pregel系统，在BSP编程模型的基础上对大规模的图对象进行处理。Mizan提出了细粒度的负载均衡。首先读取数据，将数据分区并分配给不同worker。然后整个系统执行一系列的superstep，每一个superstep都被一个全局的同步栅栏分开。在每一个超级步中，每一个顶点对来自上一个超级步中的消息进行处理，并将消息发送给邻接的顶点，以供下一个超级步计算使用。与Pregel不同的地方在于，Mizan通过在worker之间移动选择的顶点来保持整个图的负载平衡。Mizan着重于负载的运行时监控和全局的分布式顶点移动管理。在运行时，Mizan针对worker发送给其他worker的消息数量、接收的消息数量以及当前超级步的每个顶点处理消息所消耗的响应时间作为主要的监控指标。如果消息数量过多或者当个计算节点在当前超级步处理消息所消耗的响应时间过长则判定为该worker负载过重，需要进行重新分配。然后，在该worker内选择不平衡的顶点，同时将所有worker根据监控指标统计的数据进行排序。第一个和最后一个，第二个和倒数第二个，一次类图，两两编为一组，并将较为繁忙的worker的上选择的顶点移动到与之同组的较为空闲的worker上。但是，由于Mizan的该特点也势必导致在图计算的过程中顶点在不同的计算节点上的频繁移动，给计算效率造成一定的影响。

GPS[16]是一个具有可扩展性、容错、程序员友好的大规模图处理系统。它不仅提供了更加丰富的API,并且GPS开发了一套自己的领域特定语言Green-Marl[17,18]，同时可以在计算期间动态的重新为图分区。GPS通过合理的动态重新分区算法，极大的减少了各个计算节点之间的消息通讯量。在Pregel中只有以单一节点为中心的算法才可以通过Pregel的API实现，GPS则改进这一缺陷，支持多顶点组合的算法。为减少各个计算节点之间的消息通讯量，GPS提出一种LALP的分区方式，该分区方式通过将具有较高入度和出度的顶点分配到不同的节点上实现。可惜的是，GPS的扩展性是以庞大的设备数量，高昂的经济费用为代价的，在单个计算节点上存在资源浪费和利用率不高的问题，如在内存不够时，不能充分利用磁盘等。此外，GPS不能很好的处理强连通分量的相关问题。PowerGraph[19]是一个用于处理特殊幂律分布的自然图的分布式框架。PowerGraph引入一种以顶点为依据的分区方式，支持边的重复分布式存储，并且提供类似与GraphLab的gather、apply、scatter三种操作。但是，PowerGraph如何处理动态图和非幂律分布的自然图尚未可知。

除此之外，还存在一些为特别应用而定制的一些分布式框架，如Kineograph[20]和Little Engine[21]。Kineograph也是一个类Pregel系统，该系统主要用于处理不断动态变化的图对象。它可以抓取输入中数据之间的关系，在图数据结构中表示出来，同时快速创建数据快照，并且为了保证图动态变化后图数据的一致性，将图处理的过程和图更新的过程区分开来。Little Engine系统根据one-hop重复性对图进行重新分区，在整个图结构上实现负载均衡，减少网络开销。但是，该系统和Kineograph类似都是用来处理特殊问题而定制的系统，其中Kineograph主要用于从一系列流式输入的数据快照中进行快熟数据挖掘的目的，Little Engine用于处理在线社交网络的扩展性。因此，从应用层面来看，Kineograph和Little Engine的应用面过窄，无法解决大多数问题，存在一定的局限性。

综上所述，分布式的图处理系统依然存在着许多悬而未决的难题。对于采用了BSP模型的分布式系统而言，整个图的处理过程是由一系列迭代的超级步组成，相邻的超级步之间需要额外的同步等待时间，而不同计算节点之间的负载均衡问题则成为分布式系统的主要性能瓶颈之一。另外，跨不同计算节点的边会导致顶点通讯的延迟问题。从经济角度来看，在分布式系统上进行数据分析、调试和处理需要额外的资源消耗，例如计算资源以及维持计算的能源消耗。与此同时，从用户角度分析，分布式系统对开发人员也提出了较高的专业要求，增加应用的开发成本。

\subsection{单机系统}

虽然分布式系统极大的提高了图计算的效率，妥善的处理了一批亟待解决的问题。分布式框架的最大的缺陷在于分布式资源是必不可少的，同时这对开发者而言，无论是费用还是技术门槛都要求过高，并且用分布式框架开发，不方便问题定位和调试。因此，有学者就提出一些能运行于单机系统上的能够处理大规模图对象的系统。

Grace[22]是基于内存的图感知事务型图计算系统，被设计应用于要求低延迟的图计算。另外，计算机中核的数量与内存的不断增加，单个计算节点的计算能力从理论上可以替代同等配置的分布式系统，即将以往运行于分布式系统上的应用在单个计算节点上完成。在内存中，程序的访问呈现出局部性的特点，所以Grace将整个图分成较小的子图存储在内存中，将这些子图分配给不同的核并行计算。Grace为用户提供了一套完整的查询和更新图的API，查询操作可以对特定的顶点或者分区进行才，更新操作主要指添加或者删除顶点和边。但是，Grace的重点在于从图感知和事务两个方面出发，虽然考虑现代计算机多核的的特点，但是在多核之间消息的通讯方面语焉不详，避重就轻，就整个框架而言并没有充分发挥多核并行计算的优势。

Ligra[23]是一个轻量级的基于共享内存的图处理框架。该框架适用于的单机多核的并行计算的处理，使得图的基于遍历的算法简单易写。实现Ligra的图算法很灵活：针对图中边的处理，另外一种则是针对顶点。虽然Ligra充分利用了多核和并行计算的优势，在遍历算法中表现卓越。但是该框架的共享内存的特性限制其在动态图计算中的发挥，并且不适合异步计算。
Pearce[24]是一个为图遍历设计的异步式系统。该方案将表示图结构的稀疏矩阵经过压缩存储在磁盘上，顶点的value存储在内存中，计算通过并发容器调度。但是，该系统与Kineograph和Little Engine一样都是为了特殊的应用而设计，存在局限性。

Graphchi[25]是一个基于磁盘的高效图处理系统。由于个人计算机通常没有足够的内存装在整个图，所以把图存储在硬盘上，与内存相比，硬盘的数据读写速度较慢，会拖慢整个计算过程。因此，GraphChi设计了一种更快速的，减少随机读写的硬盘访问的平行滑动窗口(PSW)。PSW使用较少次数的非顺序磁盘读写快速的从硬盘中处理边和顶点，并且支持异步计算模型。PSW处理图的过程分为三个步骤：1）、从磁盘中装载图。2）、更新顶点和边。3）、将更新的值写入磁盘。Graphchi有着较好的扩展性和图处理性能，以较低的代价解决复杂的问题，是该领域一个成功的榜样。但是，Graphchi依然存在一些性能问题。首先Graphchi并发度有限，其次它将图处理过程分为计算过程和IO过程，造成计算的不连续。为此有人提出TurboGraph，它充分利用多核的高并发的特性，使计算过程和IO磁盘访问重叠，提高计算效率，减少计算时间。TurboGraph[26]提出一种pin-and-slide模型。该模型实现一种多向量相乘的列视图算法，并且设计两种不同类型的线程，执行线程和回调线程。在操作系统中，线程虽然极大的提高了程序的并发性，但是线程的切换依然是一种较为浪费操作系统资源的操作，从多核的角度考虑，TurboGraph仍然没有充分挖掘多核的优势。


\section{研究内容}
大规模图处理无论是在分布式环境还是在单机环境，都存在各种各样的问题。目前国内对该方面的研究尚处于起步阶段，很多技术尚不成熟，如何高效经济的处理大规模图像依然是一个挑战，为此我们
通过对国内外研究现状的研究情况进行分析、比较与总结，针对对大规模图数据处理课题提出如下几点主要研究内容：
\begin{itemize}
\item 研究分析现有分布式图处理系统中遗留的诸如负载均衡、通讯延迟等问题
\item 研究单机多核系统中使用角色并发模型替代传统线程并发模型以提高并发量，增加系统的处理数据的吞吐量的可能性。
\item 分析传统BSP模型在计算处理过程中存在的强耦合处理流程的弊端，并在角色并发的模型基础上对传统BSP并发模型进行改进
\item 实现一个具有可扩展性、兼容性、便捷高效，同时能够充分发挥单机多核计算能力的图处理框架。
\end{itemize}

\section{研究课题的来源}